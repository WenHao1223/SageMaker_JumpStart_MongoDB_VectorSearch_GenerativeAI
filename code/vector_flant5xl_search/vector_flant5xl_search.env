#MongoDB Credentials
MONGO_URI = "<enter the MongoDB Connection String including username and password>"
MONGO_DB="<enter the MongoDB Database Name>"
MONGO_COLLECTION="<enter the Collection Name>"

#MongoDB Vector Parameters
FIELD_NAME_TO_BE_VECTORIZED="<enter the field name that need to be vectorized>"
VECTOR_FIELD_NAME="egVector"
INDEX_NAME="<enter a name for Vector Search Index>"

# Model used for Embedding
EMBEDDING_ENDPOINT_NAME="jumpstart-dft-prtnr-hf-textembedding-all-minilm-l6-v2"

# Flan-T5-XL Model used for Text2Text - Chatbot, Translation to MultiLanguage , Text Summary
CHATBOT_ENDPOINT_NAME = 'jumpstart-dft-hf-text2text-flan-t5-xl'

## LLM Text2text Flan-T5-XL model parameters
MAX_LENGTH="50"
NUM_RETURN_SEQUENCES="1"
TOP_K="50"
TOP_P="0.95"
DO_SAMPLE="True"
TEMPERATURE="1"

# what you want to search (Semantic Search) in the MongoDB Atlas Collection
SEARCH_VARIABLE="worst experience"

# update the prompts for the llm model. Prompt play a cruical part in getting the relevant answers. Sample for each scenario is given below.
PROMPT_QUESTION_TO_CHATBOT="Translate the content to French"

##################################################################

# Guidance on prompting and parameters for various scenarios 
#courtsey: https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/text2text-generation-flan-t5-ul2.ipynb

# 1. Summarization
    # Sample Prompts and parameter values
        #     "Briefly summarize this sentence:",
        #     "Write a short summary for this text:",
        #     "Generate a short summary this sentence:\n",
        #     "Write a brief summary in a sentence or less\n",
        #     "Summarize the given text in a single phrase: ",
        #     "Can you generate a short summary for the given content? :",
        #     "Write a sentence based on this summary:",
        #     "Write a sentence based on ",
        #     "Summarize this article:\n\n",

    # parameters
        # MAX_LENGTH="50"
        # NUM_RETURN_SEQUENCES="3"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

# 2. Common sense reasoning / natural language inference
    # Sample Prompts and parameter values : "Based on the content can we conclude that the customers are happy ?\n options: yes / no "

    # Based on the content can we conclude that "\"{hypothesis}\"?\n\n{options_}",
    # Based on the paragraph can we conclude that this sentence is true?\n{hypothesis}\n\n{options_}""",
    # Can we draw the following conclusion based on the given input ?\n{hypothesis}\n\n{options_}""",
    # Does this next sentence follow, given the preceding text?\n{hypothesis}\n\n{options_}""",
    # Can we infer the following?\n{hypothesis}\n\n{options_}""",
    # Read the following paragraph and determine if the hypothesis is true:\n\n{premise}\n\nHypothesis: {hypothesis}\n\n{options_}""",
    # Read the text and determine if the sentence is true:\n\n{premise}\n\nSentence: {hypothesis}\n\n{options_}""",
    # Can we draw the following hypothesis from the context? \n\nContext:\n\n{premise}\n\nHypothesis: {hypothesis}\n\n{options_}""",
    # Determine if the sentence is true based on the text below:\n{hypothesis}\n\n{premise}\n{options_}""",

    # parameters
        # MAX_LENGTH="50"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

# 3. Question and Answering
    # Sample Prompts and parameter values : "Read this article and answer this question \n which apparel the customer like most? "
    
    # Answer based on context: \n\n{question}?
    # Answer this question based on the article: {question} ?
    # question ?
    # Answer this question: {question}?,
    # Read this article and answer this question \n{question} ?,
    # Based on the given content, answer a question. {question}?
    # Write an article that answers the following question: {question} based on the content.

    # parameters
        # MAX_LENGTH="50"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

# 4. Sentence / Sentiment Classification
    # Sample Prompts and parameter values : "What is the sentiment of the following content ?\n options: Postive / Negative / Neutral / Cannot Decide"
    
    #Review the content and say if this review negative or positive?\n{options_}""",
    #Short review of the content: \nDid the critic think positively or negatively?\n{options_}""",
    #Sentence from a review: \nWas the reviews seen positively or negatively based on the preceding review? \n\n{options_}""",
    #How would the sentiment of this content be perceived?\n\n{options_}""",
    #Is the sentiment of the content is positive or negative?\n{options_}""",
    #What is the sentiment of the following content ?\n{options_}""",

    # parameters
        # MAX_LENGTH="50"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

# 5. Translation
    # Sample Prompts and parameter values : "Translate the content to German"
    
    # Translate the content to {lang}
    # Could you please translate the content to {lang2}?
    # Translate to {lang2}
    # Translate the following sentence to {lang2}:
    # How is the content said in {lang2}?


    # parameters
        # MAX_LENGTH="50"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"


# 5. Imaginary article generation based on a Content
    # Sample Prompts and parameter values : "Given the Content, articulate an imaginary article"
    
    # Given the Content, articulate an imaginary article.


    # parameters
        # MAX_LENGTH="5000"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

        

# 6. Summarize a title based on the article
    # Sample Prompts and parameter values : "Give me a good title for the content above"
    
    # Give me a good title for the content above.


    # parameters
        # MAX_LENGTH="5000"
        # NUM_RETURN_SEQUENCES="1"
        # TOP_K="50"
        # TOP_P="0.95"
        # DO_SAMPLE="True"
        # TEMPERATURE="1"

#Details on parameters

# # Advanced features
# # This model also supports many advanced parameters while performing inference. They include:
# # max_length: Model generates text until the output length (which includes the input context length) reaches max_length. If specified, it must be a positive integer.
# # num_return_sequences: Number of output sequences returned. If specified, it must be a positive integer.
# # num_beams: Number of beams used in the greedy search. If specified, it must be integer greater than or equal to num_return_sequences.
# # no_repeat_ngram_size: Model ensures that a sequence of words of no_repeat_ngram_size is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.
# # temperature: Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If temperature -> 0, it results in greedy decoding. If specified, it must be a positive float.
# # early_stopping: If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.
# # do_sample: If True, sample the next word as per the likelihood. If specified, it must be boolean.
# # top_k: In each step of text generation, sample from only the top_k most likely words. If specified, it must be a positive integer.
# # top_p: In each step of text generation, sample from the smallest possible set of words with cumulative probability top_p. If specified, it must be a float between 0 and 1.
# # seed: Fix the randomized state for reproducibility. If specified, it must be an integer.
# # We may specify any subset of the parameters mentioned above while invoking an endpoint. Next, we show an example of how to invoke endpoint with these arguments
